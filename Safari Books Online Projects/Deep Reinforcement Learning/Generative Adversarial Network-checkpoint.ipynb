{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers import Activation, Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_conv2d(x, output_space):\n",
    "    return Conv2DTranspose(output_space, kernel_size=5,strides=2, padding='same',\n",
    "                           kernel_initializer=tf.random_normal_initializer(mean=0.0,stddev=0.02))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = \"./apple.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144722, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  36,  79,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 134, 238,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 119, 254,   4,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 101, 255,  21,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  82, 255,  39,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64,\n",
       "       255,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  46, 255,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  28, 255,  94,   0,   2,  24,  44,   9,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,\n",
       "        67, 135, 203, 253, 255, 255, 255, 245, 238, 253, 255, 255, 234,\n",
       "       127,  19,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  53,\n",
       "       185, 246, 255, 246, 185, 127, 119, 120, 251, 197, 136, 124,  98,\n",
       "        84, 169, 252, 213,   8,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        47, 239, 222, 135,  67,   8,   0,   0,   0,   0, 201, 112,   0,\n",
       "         0,   0,   0,   0,  78, 255,  65,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 197, 223,  25,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  24, 255, 100,   0,   0,   0,   0,\n",
       "         0,   0,   0,  11, 250, 123,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1, 244, 134,   0,   0,\n",
       "         0,   0,   0,   0,   0,  54, 255,  71,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  12,   2,   0,   0, 211, 169,\n",
       "         0,   0,   0,   0,   0,   0,   0,  58, 255, 137,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   1, 229, 125,   0,   0,\n",
       "       176, 203,   0,   0,   0,   0,   0,   0,   0,  58, 255, 213,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33, 255, 199,\n",
       "         0,   0, 142, 237,   0,   0,   0,   0,   0,   0,   0,  51, 255,\n",
       "       229,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  94,\n",
       "       255, 251,  15,   0, 108, 255,  17,   0,   0,   0,   0,   0,   0,\n",
       "        29, 255, 244,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 197, 238, 255,  78,   0,  80, 255,  47,   0,   0,   0,   0,\n",
       "         0,   0,   6, 248, 255,   5,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  48, 255, 107, 236, 178,   0, 138, 246,  12,   0,   0,\n",
       "         0,   0,   0,   0,   0, 194, 255,  28,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 154, 241,  12, 105, 255,  89, 223, 173,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 130, 255,  80,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  16, 244, 147,   0,   1, 192, 248, 255,\n",
       "        88,   0,   0,   0,   0,   0,   0,   0,   0,  31, 243, 151,   0,\n",
       "         0,   0,   0,   0,   0,   0,  35, 204, 251,  41,   0,   0,  21,\n",
       "       162, 176,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0, 143,\n",
       "       249,  39,   0,   0,   0,   0,   0,  88, 241, 232,  68,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  21, 230, 232,  65,  19,  23, 111, 212, 255, 188,  24,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  33, 216, 255, 255, 255, 254, 192,  90,   2,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  16,  81, 105, 109,  35,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144722, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data/255\n",
    "data = np.reshape(data,(data.shape[0], 28,28,1))\n",
    "img_w, img_h = data.shape[1:3]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bde6ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[4242,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_builder(depth=64, p=0.4):\n",
    "    # Define input\n",
    "    inputs = Input((img_w, img_h,1))\n",
    "    \n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(depth*1, 5, strides=2, padding='same', activation='relu')(inputs)\n",
    "    conv1 = Dropout(p)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(depth*2, 5, strides=2, padding='same', activation='relu')(conv1)\n",
    "    conv2 = Dropout(p)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(depth*4, 5, strides=2, padding='same', activation='relu')(conv2)\n",
    "    conv3 = Dropout(p)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(depth*8, 5, strides=1, padding='same', activation='relu')(conv3)\n",
    "    conv4 = Flatten()(Dropout(p)(conv4))\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(conv4)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                      optimizer=RMSprop(lr=0.0008, decay=6e-8, clipvalue=1.0),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_builder(z_dim=100, depth=64, p=0.4):\n",
    "    inputs = Input((z_dim,))\n",
    "    \n",
    "    # First dense layer\n",
    "    dens1 = Dense(7*7*64)(inputs)\n",
    "    dens1 = BatchNormalization(momentum=0.9)(dens1)\n",
    "    dens1 = Activation(activation='relu')(dens1)\n",
    "    dens1 = Reshape((7,7,64))(dens1)\n",
    "    \n",
    "    # De-convolutions layers\n",
    "    conv1 = UpSampling2D()(dens1)\n",
    "    conv1 = Conv2DTranspose(int(depth/2), kernel_size=5,padding='same',activation=None,)(conv1)\n",
    "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "    conv1 = Activation(activation='relu')(conv1)\n",
    "    \n",
    "    conv2 = UpSampling2D()(conv1)\n",
    "    conv2 = Conv2DTranspose(int(depth/4), kernel_size=5,padding='same',activation=None,)(conv2)\n",
    "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "    conv2 = Activation(activation='relu')(conv2)\n",
    "    \n",
    "    conv3 = Conv2DTranspose(int(depth/8), kernel_size=5,padding='same',activation=None,)(conv2)\n",
    "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "    conv3 = Activation(activation='relu')(conv3)\n",
    "    \n",
    "    output = Conv2D(1, kernel_size=5, padding='same', activation='sigmoid')(conv3)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 8)         3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 1)         201       \n",
      "=================================================================\n",
      "Total params: 396,961\n",
      "Trainable params: 390,577\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_builder(z_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = RMSprop(lr=0.0004,decay=3e-8,clipvalue=1.0),\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_2 (Model)              (None, 28, 28, 1)         396961    \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 4,708,514\n",
      "Trainable params: 4,702,130\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial_model = adversarial_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144722, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1000, batch=128):\n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        real_imgs = np.reshape(data[np.random.choice(data.shape[0],batch,replace=False)],(batch,28,28,1))\n",
    "        fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 100]))\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            real_imgs.shape\n",
    "            \n",
    "        x = np.concatenate((real_imgs,fake_imgs))\n",
    "        y = np.ones([2*batch,1])\n",
    "        y[batch:,:] = 0\n",
    "        \n",
    "        make_trainable(discriminator, True)\n",
    "        \n",
    "        d_metrics.append(discriminator.train_on_batch(x,y))\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        \n",
    "        make_trainable(discriminator, False)\n",
    "        \n",
    "        noise = np.random.normal(loc=0,scale=1,size=[batch, 100])\n",
    "        y = np.ones([batch,1])\n",
    "\n",
    "        a_metrics.append(adversarial_model.train_on_batch(noise,y)) \n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        if (i+1)%500 == 0:\n",
    "\n",
    "            print('Epoch #{}'.format(i+1))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, running_d_loss/i, running_d_acc/i)\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, running_a_loss/i, running_a_acc/i)\n",
    "            print(log_mesg)\n",
    "\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "\n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k+1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return a_metrics, d_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeramie.goodwin\\AppData\\Local\\Continuum\\anaconda3\\envs\\DLProject\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "a_metrics_complete, d_metrics_complete = train(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
